% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dependentLCM_fit.r
\name{dependentLCM_fit}
\alias{dependentLCM_fit}
\title{Fits a bayesian dependent LCM model}
\usage{
dependentLCM_fit(
  nitr,
  df = NULL,
  mat = NULL,
  nclass = NCLASS,
  ndomains = NULL,
  class2domain = CLASS2DOMAINS[1],
  classPi_alpha = CLASSPI_ALPHA,
  domain_maxitems = NULL,
  theta_alpha = THETA_ALPHA,
  domain_proposal_empty = DOMAIN_PROPOSAL_EMPTY,
  domain_nproposals = NULL,
  domain_theta_prior_type = DOMAIN_THETA_PRIOR_TYPE[1],
  class_pi = NULL,
  classes = NULL,
  domains = NULL,
  steps_active = STEPS_ACTIVE,
  save_itrs = SAVE_ITRS,
  class_init_method = CLASS_INIT_METHODS[1],
  warmup_settings = "default",
  warmup_dlcm = NULL,
  domainPriorKnowledgeLog = NULL,
  print_itrs = Inf
)
}
\arguments{
\item{nitr}{integer. Number of iterations to run the bayes MCMC}

\item{df}{dataframe. The data you wish to analyze. Should describe nominal data. Factor columns work best, but we make an honest effort to interpret any values given (see getStart_matrix()). This will be converted into an integer matrix (see 'matrix' argument). This 'matrix' argument takes precedence over the 'df' argument; only one of these two arguments is needed. Assumes no missing data (NA rows will be dropped).}

\item{mat}{matrix. The data you wish to analyze. Should be an integer matrix describing nominal data. Each column should take values 0, 1, 2, ..., max-for-this-column. Assumptions: i) In each column the maximum value is achieved for atleast one observation. ii) There are no NAs.}

\item{nclass}{integer. Number of subject latent classes}

\item{ndomains}{integer. Number of item domains}

\item{class2domain}{integer vector of length nclass. Classes with same value have same domains.
If "HOMO" then defaults to c(0,0,...). If "HET" then defaults to c(0, 1, 2, ...)}

\item{classPi_alpha}{numeric vector. Bayes hyperparameter giving prior for Pi.}

\item{domain_maxitems}{iinteger. Maximum number of items which can be in a domain. Default is 10 (beyond 10 runs slowly).}

\item{theta_alpha}{numeric. Bayes hyperparemter giving the prior for theta/probabilties.}

\item{domain_proposal_empty}{numeric. Sets how often the domain metropolis proposal function pairs a nonempty domain with an empty domain.}

\item{domain_nproposals}{Sets how many times the domain metropolis propsal function is called each iteration}

\item{domain_theta_prior_type}{string. Defines what sort of prior is used for domains and theta. One of the following.
\itemize{
\item{"permissive=}{ recommended/default. has moderate regularization on domains. Domain uses "balls in buckets" prior, and theta uses dirichlet prior.}
\item{"restrictive=}{ has strong regularization on domains. As permissive, but domain prior is adjusted further to cancel out any theta prior.}
\item{"niave=}{ no regularization on domains. Bad outcomes result. For demonstration purposes only. Assumes all domains are equally likely.}
}}

\item{class_pi}{numeric vector size nclass. Initial condition for bayes parameter pi.}

\item{classes}{integer vector size nrow(df). Initial condition for subject classes.}

\item{domains}{list. Initial values for domains/probabilites. Should be of the form:
domains = list(
class1 = list(
  domain1 = list(
    items = c(...) # items in this domain
    , thetas = c(...) # probabilities of each response to these items ordered per dependentLCM::id2pattern()
  )
  , domain2 = list(items=c(...), thetas=c(...))
  , ...
)
, class2 = list(
  domain1 = list(items=c(...), thetas=c(...))
  , domain2 = list(items=c(...), thetas=c(...))
  , ...
)
, ...
)}

\item{steps_active}{Named boolean vector of what actions to take during mcmc. If mcmc is skipped then initial values are kept as fixed.
\itemize{
\item{"thetas=TRUE"}{ to do gibbs on response probabilities}
\item{"domains=TRUE"}{ to do metropolis on domains}
\item{"class_pi=TRUE"}{ to do gibbs on class prior}
\item{"classes=TRUE"}{ to do gibbs on class membership}
\item{"identifiable=TRUE"}{ to check generic identifiability conditions of domains}
\item{"likelihood=TRUE"}{ to get the likelihood that each observation is in each class}
\item{"class_collapse=TRUE"}{ to collapse on theta when sampling classes}
}}

\item{save_itrs}{Named numeric vector. Gives the maximum number of MCMC iterations which should be saved. Can set components to infinity to get data from every iteration.
\itemize{
\item{"domains_accept=#}{ for saving domain metropolis accept/reject choices.}
\item{"class_loglik=#}{ saves the probability that a response is observed conditional on each class}
\item{"class_loglik_collapsed=#}{ as class_loglik but after collapsing on response probabilities}
\item{"agg_loglik=#}{ saves aggregate likelihood of each iteration}
\item{"classes=#}{ saves the class vector of each iteration.}
\item{"class_counts=#}{ saves the number of times an observation is in each class.}
\item{"all=#}{ saves everything. If lower, takes precidence over other terms.}
}}

\item{class_init_method}{string. Decides how 'classes' is defaulted if NULL. One of "kmodes" or "random" or "random_centers", "random_centers_polar"}

\item{warmup_settings}{list. Optionally allows for an extra warmup cycle using different parameters vs the arguments given for the main process. Any parameters in the given list will overwrite the arguments of the same name in the warmup cycle.}

\item{warmup_dlcm}{list. A past DLCM fit (from dependentLCM_fit). The last iteration of the DLCM is used as the Bayes parameters.}

\item{domainPriorKnowledgeLog}{Numeric. An nitem*nitem upper triangular matrix. Values of zero indicate no prior knowledge of the domain structure. Values greater than zero indicate that this pair of items should be more likely to be in the same domain. Values less than zero indicate that this pair of items should be less likely to be in the same domain.}

\item{print_itrs}{Integer. Optional. Prints progress by printing every print_itrs iterations.}
}
\value{
Returns a list with three items. hparams describes the hyperparmeters chosen by the model. These match the arguments input into the function plus any default values. mcmc describes the simulated (fitted) bayes parameter values. warmup describes extra/special warmup iterations using the 'warmup_settings' argument.

The mcmc item includes the following values. mcmc does NOT discard any warmup iterations.
\itemize{
\item{"class_pi"}{=A matrix describing the prior class probabilities of each class in each MCMC iteration. It contains one row per class one column per iteration, and each cell contains the prior probability of a subject being in that class.}
\item{"classes"}{=A matrix describing what class each subject belongs to. It contains one row per subject, one column per MCMC iteration, and each cell identifies the class of that subject in that iteration.}
\item{"nitr"}{=Gives the total number of iterations processed including warmup iterations}
\item{"domains_accept"}{=Each MCMC iteration, we attempt to change the domain structure #domain_nproposals times with a metropolis step. This 3-dimensional array describes whether the proposed change was accepted or rejected. A value of -2 indicates the proposal was rejected due to identifiability or max item constraints. A value of -1 or 2 indicates the proposed change is (equivalent to) no change. A value of 0 indicates the proposal was rejected. A value of 1 indicates the proposal was accepted.. The dimensions of the array are as follows. The third dimension has one slice per iteration. The first dimension gives one slice per 'domain_nproposals'. The second dimension has between 1 and nclass slices. A homogeneous DLCM has 1 slice, a heterogeneous DLCM has nclass slices, and a partially heterogeneous DLCM may be in-between.}
\item{"class_loglik"}{=A 3-dimensional array. The first dimension has one slice per class. The second dimension has one slice per subject/observation. The third dimension has one slice per MCMC iteration. Each cell contains the log likelihood that we would observe the response pattern given by this subject, if the subject was in this class, based on the parameters in this iteration.}
\item{"troubleshooting"}{=Used for investigationg bugs. Should be empty.}
\item{".Random.seed"}{=The state of the random seed before this function was executed. If you set the seed to this state and run again you should get the same result.}
\item{"domains"}{=Dataframe with one row for iteration X domain X pattern. For an MCMC iteration, it identifies what domains there are, and for each class what's the probability of getting a given response pattern to a given domain. It contains the following columns:
\itemize{
\item{"itr"}{=What MCMC iteration is this?}
\item{"class"}{=What class are we calculating the response probabilities for?}
\item{"domain"}{=ID. What domain is this?}
\item{"pattern_id"}{=Integer uniquely identifying a response pattern to thie items in this domain. We will calculate the probability of this response pattern. pattern_id needs to be paired with a items_id to make sense of it.}
\item{"items_id"}{=Integer uniquely identifying what items (what set of items) are in this domain.}
\item{"class2domain"}{=For heterogeneous and partially heterogeneous DLCMs, this identifies which group of latent classes this domain belongs to.}
\item{"prob"}{=What's the probability of getting this response pattern?}
\item{"nitems"}{=How many items are in this domain?}
\item{items"}{=String listing the items in this domain. Function of items_id.}
\item{item_#"}{=For each item #, gives the specific value of that item in this response pattern. A value of -1 indicates this item is not in this domain. item_# is a function of (items_id, pattern_id).}
}}
\item{"domains_merged"}{=Dataframe describing what domains were chosen for each MCMC iteration. There is one row for MCMC iteratation X class2domain. For (partially) heterogeneous DLCMs, class2domain allows different classes to have different domains. The string column domains_merged describes the domains with vertical bars "|" separating domains, and commas "," separating items wtihin a given domain.}
\item{"runtimes"}{=Describes how long the function ran in seconds. pre records the seconds of preprocessing before starting MCMC. mcmc describes how long it took to run the mcmc iterations. post describes how long it took to aggregate/transform the data after the MCMC is completed. Total gives the total time. There are 'secret' troubleshooting steps to get the runtime of specific C++ functions executed by this algorithm (these are stored under 'troubleshooting').}
}
}
\description{
Fits a bayesian dependent LCM model
}
\examples{
\dontrun{
library(dependentLCM)

# Get Data
library(pks)
data(probability, package="pks")
xdf <- na.omit(probability[,c("b101", "b102", "b103", "b104", "b105", "b106", "b107", "b108", "b109", "b110", "b111", "b112", "b201", "b202", "b203", "b204", "b205", "b206", "b207", "b208", "b209", "b210", "b211", "b212")])

# Run Model
set.seed(4)
dlcm <- dependentLCM_fit(
  nitr = 6000
  , save_itrs=c(all=6000-1000) # warmup of 1000 used here
  , df=xdf
  , nclass=3
  , class2domain = "HOMO"
)
dlcm$summary <- dlcm.summary(dlcm)


# Class of each observation
dlcm$summary$classes

# Which items are grouped together because they show local dependence? See ?dlcm.summary. We call groups of locally dependent items 'domains'.
dlcm$summary$domain_items_all

# Average response probabilities
dlcm$summary$thetas_avg_mode
}
}
